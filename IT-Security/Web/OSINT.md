Open-Source Intelligence
discovering information (about your target website), these resources are often referred to as OSINT or (Open-Source Intelligence) as they're freely available tools that collect information.

# Google
using Google search engine to find specific information https://en.wikipedia.org/wiki/Google_hacking
with `""` you can require specific search terms in the results
with additional filters you can specify the search:
Filter | Example | Description
--- | --- | ---
site | site:URL | returns results only from the specified website address
inurl | inurl:admin | returns results that have the specified word in the URL
filetype | filetype:pdf | returns results which are a particular file extension
intitle | intitle: admin | returns results that contain the specified word in the title
example of a combination: `site:URL "admin"`

# Robots.txt and sitemap.xml
have a look at (disallowed) `URL/robots.txt` entries (or maybe at `URL/sitemap.xml` as well) to find hidden web directories and files

# Wappalyzer
online tool and browser extension that helps identify what technologies a website uses, such as frameworks, Content Management Systems (CMS), payment processors etc... and often with version number
Download URL: https://www.wappalyzer.com/


# Wayback Machine
historical archive of websites that dates back to the late 90s
shows scraped websites and saved content in a timeline
https://archive.org/web/

# Github
Online VCS repositories to the the source code of public repositories